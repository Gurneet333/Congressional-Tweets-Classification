{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "import re\n",
    "import time\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd  \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from gensim.models import Phrases\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from pyLDAvis import sklearn as sklearn_lda\n",
    "import pickle \n",
    "import pyLDAvis.gensim_models\n",
    "import os\n",
    "from nltk.tokenize import RegexpTokenizer,sent_tokenize,word_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "from gensim.models import CoherenceModel\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"E:/UOR Notes/Stats for Machine Learning/Assignments/Kaggle Assignment/\"\n",
    "training_input_file = \"Processed_Training_Data_comb_1.csv\"\n",
    "testing_input_file = \"Processed_Testing_Data_Comb1.csv\"\n",
    "training_input_path = input_dir+training_input_file\n",
    "testing_input_path = input_dir + testing_input_file\n",
    "random.seed(265)  #Setting random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>full_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>year</th>\n",
       "      <th>party_id</th>\n",
       "      <th>Cleaned_Text_WO_Stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>b\"RT @KUSINews: One of our longtime viewers wa...</td>\n",
       "      <td>KUSI</td>\n",
       "      <td>10</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>R</td>\n",
       "      <td>kusinews one longtime viewer congressman darre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>b\"Today I'm urging the @CDCgov to immediately ...</td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>111</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>R</td>\n",
       "      <td>urging cdcgov immediately launch phone hotline...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>b'Tomorrow, #MO03 seniors graduate from Calvar...</td>\n",
       "      <td>MO03</td>\n",
       "      <td>2</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>R</td>\n",
       "      <td>tomorrow #mo03 senior graduate calvary luthera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>b'Congrats to #TeamUSA and Canton Native @JGre...</td>\n",
       "      <td>TeamUSA WorldJuniors</td>\n",
       "      <td>3</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>R</td>\n",
       "      <td>congrats #teamusa canton native jgreenway12 wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>b'Pleased to support @amergateways at their Ju...</td>\n",
       "      <td>ImmigrantHeritageMonth</td>\n",
       "      <td>3</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>D</td>\n",
       "      <td>pleased amergateways june fiesta honored #immi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  favorite_count  \\\n",
       "0           0               0   \n",
       "1           1             258   \n",
       "2           2               0   \n",
       "3           3               9   \n",
       "4           4               3   \n",
       "\n",
       "                                           full_text                hashtags  \\\n",
       "0  b\"RT @KUSINews: One of our longtime viewers wa...                    KUSI   \n",
       "1  b\"Today I'm urging the @CDCgov to immediately ...             Coronavirus   \n",
       "2  b'Tomorrow, #MO03 seniors graduate from Calvar...                    MO03   \n",
       "3  b'Congrats to #TeamUSA and Canton Native @JGre...    TeamUSA WorldJuniors   \n",
       "4  b'Pleased to support @amergateways at their Ju...  ImmigrantHeritageMonth   \n",
       "\n",
       "   retweet_count    year party_id  \\\n",
       "0             10  2017.0        R   \n",
       "1            111  2020.0        R   \n",
       "2              2  2014.0        R   \n",
       "3              3  2017.0        R   \n",
       "4              3  2019.0        D   \n",
       "\n",
       "                           Cleaned_Text_WO_Stopwords  \n",
       "0  kusinews one longtime viewer congressman darre...  \n",
       "1  urging cdcgov immediately launch phone hotline...  \n",
       "2  tomorrow #mo03 senior graduate calvary luthera...  \n",
       "3  congrats #teamusa canton native jgreenway12 wi...  \n",
       "4  pleased amergateways june fiesta honored #immi...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cong_tweets_data = pd.read_csv(training_input_path)\n",
    "cong_tweets_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>full_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>year</th>\n",
       "      <th>party</th>\n",
       "      <th>Cleaned_Text_WO_Stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>b'#TaxReform improved the playing field for Am...</td>\n",
       "      <td>TaxReform</td>\n",
       "      <td>13</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>D</td>\n",
       "      <td>#taxreform improved playing field worker busin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>b'This #NativeWomensEqualPay Day, we recommit ...</td>\n",
       "      <td>NativeWomensEqualPay</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>#nativewomensequalpay recommit passing paychec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>b\"\\xe2\\x80\\x9cI became convinced that our gene...</td>\n",
       "      <td>MeToo ShatteringTheSilence</td>\n",
       "      <td>24</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>D</td>\n",
       "      <td>became convinced generation silence make compl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>b'During #NationalAdoptionMonth, we honor the ...</td>\n",
       "      <td>NationalAdoptionMonth</td>\n",
       "      <td>2</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>D</td>\n",
       "      <td>#nationaladoptionmonth honor adoptive parent p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>b'Happy #AirborneDay to our @USArmy paratroope...</td>\n",
       "      <td>AirborneDay AirborneAllTheWay</td>\n",
       "      <td>7</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>D</td>\n",
       "      <td>happy #airborneday usarmy paratrooper veteran ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Id  favorite_count  \\\n",
       "0           0   0              70   \n",
       "1           1   1              27   \n",
       "2           2   2              49   \n",
       "3           3   3              14   \n",
       "4           4   4              13   \n",
       "\n",
       "                                           full_text  \\\n",
       "0  b'#TaxReform improved the playing field for Am...   \n",
       "1  b'This #NativeWomensEqualPay Day, we recommit ...   \n",
       "2  b\"\\xe2\\x80\\x9cI became convinced that our gene...   \n",
       "3  b'During #NationalAdoptionMonth, we honor the ...   \n",
       "4  b'Happy #AirborneDay to our @USArmy paratroope...   \n",
       "\n",
       "                        hashtags  retweet_count    year party  \\\n",
       "0                      TaxReform             13  2018.0     D   \n",
       "1           NativeWomensEqualPay             11     NaN     D   \n",
       "2     MeToo ShatteringTheSilence             24  2017.0     D   \n",
       "3          NationalAdoptionMonth              2  2019.0     D   \n",
       "4  AirborneDay AirborneAllTheWay              7  2018.0     D   \n",
       "\n",
       "                           Cleaned_Text_WO_Stopwords  \n",
       "0  #taxreform improved playing field worker busin...  \n",
       "1  #nativewomensequalpay recommit passing paychec...  \n",
       "2  became convinced generation silence make compl...  \n",
       "3  #nationaladoptionmonth honor adoptive parent p...  \n",
       "4  happy #airborneday usarmy paratrooper veteran ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cong_testing_data = pd.read_csv(testing_input_path)\n",
    "cong_testing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_tweets_data['Cleaned_Text_WO_Stopwords'].dropna(inplace=True)\n",
    "docs = np.array(cong_tweets_data['Cleaned_Text_WO_Stopwords'])\n",
    "docs = [doc for doc in docs if str(doc) != 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def docs_preprocessor(docs):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    print(len(docs))\n",
    "    for idx in range(len(docs)):\n",
    "        #print(idx)\n",
    "        #print(docs[idx])\n",
    "                #docs[idx] = [[word.lower() for word in docs[idx].split()] for line in data] # Convert to lowercase.\n",
    "        docs[idx] = tokenizer.tokenize(docs[idx])  # Split into words.\n",
    "        #print(docs[idx])\n",
    "            # Remove numbers, but not words that contain numbers.\n",
    "    docs_token = [[token.lower() for token in doc if not token.isdigit()] for doc in docs]\n",
    "\n",
    "            # Remove words that are only one character.\n",
    "    docs = [[token for token in doc if len(token) > 3] for doc in docs]\n",
    "\n",
    "            # Lemmatize all words in documents.\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in docs]\n",
    "\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592803\n"
     ]
    }
   ],
   "source": [
    "docs = docs_preprocessor(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.phrases.Phrases at 0x15fd74a4848>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram = Phrases(docs, min_count=10)\n",
    "bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in initital documents: 260893\n",
      "Number of unique words after removing rare and common words: 29198\n",
      "Number of unique tokens: 29198\n",
      "Number of documents: 592803\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary representation of the documents.\n",
    "dictionary = Dictionary(docs)\n",
    "print('Number of unique words in initital documents:', len(dictionary))\n",
    "\n",
    "# Filter out words that occur less than 10 documents, or more than 20% of the documents.\n",
    "dictionary.filter_extremes(no_below=10, no_above=0.2)\n",
    "print('Number of unique words after removing rare and common words:', len(dictionary))\n",
    "\n",
    "corpus = [dictionary.doc2bow(doc) for doc in docs]\n",
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "13337.203060626984\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'event_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-e02d2470ebf5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mcoherence_lda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcoherence_model_lda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_coherence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0minter_topic_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Event Name\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mevent_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[0minter_topic_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Number of Topics\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0minter_topic_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Coherence Score\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcoherence_lda\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'event_name' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Set training parameters.\n",
    "num_topics = range(5,6)\n",
    "chunksize = 100 # size of the doc looked at every pass\n",
    "passes = 20 # number of passes through documents\n",
    "iterations = 400\n",
    "eval_every = 1  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "topic_hp_df = pd.DataFrame(columns = [\"Event Name\",\"Number of Topics\",\"Coherence Score\",\"Perplexity Score\",\"Iterations\",\"Chunksize\",\"Time Taken\",\"Keywords in Topics\"])\n",
    "\n",
    "\n",
    "for num in num_topics:\n",
    "    print(num)\n",
    "    inter_topic_df = pd.DataFrame(columns = [\"Event Name\",\"Number of Topics\",\"Coherence Score\",\"Perplexity Score\",\"Iterations\",\"Chunksize\",\"Time Taken\",\"Keywords in Topics\"])\n",
    "    # Make a index to word dictionary.\n",
    "    if len(dictionary)>0:\n",
    "        temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "        start = time.time()\n",
    "        id2word = dictionary.id2token\n",
    "        model = LdaModel(corpus=corpus, id2word=id2word, chunksize=chunksize,alpha='auto', eta='auto', iterations=iterations, num_topics=num,passes=passes, eval_every=eval_every)\n",
    "        end = time.time()\n",
    "        print(end-start)\n",
    "        time_taken = end-start\n",
    "\n",
    "        Y = model.print_topics(num_words = 10)\n",
    "        topic_words_list = []\n",
    "        for i in range(0,len(Y)):\n",
    "            #topic_words_list.append(html.Br())\n",
    "            topic_words_list.append(\"Topic \"+str(i+1)+\": \")\n",
    "            X = Y[i][1]\n",
    "            a = X.split(\"+\")\n",
    "            words_str = \"\"\n",
    "            for j in range(0,len(a)):\n",
    "                p = a[j].split(\"*\")[1].replace(\"\\\"\",\"\")\n",
    "                words_str += p\n",
    "            topic_words_list.append(words_str)\n",
    "\n",
    "        perplexity = model.log_perplexity(corpus)\n",
    "        coherence_model_lda = CoherenceModel(model=model, texts=docs, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_lda = coherence_model_lda.get_coherence()\n",
    "        \n",
    "        \n",
    "        inter_topic_df[\"Number of Topics\"] = [num]\n",
    "        inter_topic_df[\"Coherence Score\"] = [coherence_lda]\n",
    "        inter_topic_df[\"Perplexity Score\"] = [perplexity]\n",
    "        inter_topic_df[\"Iterations\"] = [iterations]\n",
    "        inter_topic_df[\"Chunksize\"] = [chunksize]\n",
    "        inter_topic_df[\"Time Taken\"] = [time_taken]\n",
    "        inter_topic_df[\"Keywords in Topics\"] = [topic_words_list]\n",
    "        topic_hp_df = pd.concat([topic_hp_df,inter_topic_df])\n",
    "        \n",
    "\n",
    "\n",
    "#topic_hp_df.to_csv(input_dir+\"Topic_Modelling_Hyperparameter_Tuning.csv\")\n",
    "#topic_hp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'favorite_count', 'full_text', 'hashtags',\n",
       "       'retweet_count', 'year', 'party_id', 'Cleaned_Text_WO_Stopwords'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cong_tweets_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_train = cong_tweets_data\n",
    "train_vecs = []\n",
    "for i in range(tweet_train.shape[0]):\n",
    "    #print(i)\n",
    "    top_topics = (\n",
    "        model.get_document_topics(corpus[i],\n",
    "                                      minimum_probability=0.0)\n",
    "    )\n",
    "    #print(top_topics)\n",
    "    topic_vec = [top_topics[j][1] for j in range(5)]\n",
    "    topic_vec.extend([tweet_train.iloc[i].favorite_count])\n",
    "    topic_vec.extend([tweet_train.iloc[i].retweet_count])\n",
    "    topic_vec.extend([len(tweet_train[\"full_text\"].iloc[i])])\n",
    "    train_vecs.append(topic_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    " \n",
    "# Encode labels in column 'species'.\n",
    "cong_tweets_data['encoded_party']= label_encoder.fit_transform(cong_tweets_data[\"party_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Val f1: 0.600 +- 0.001\n",
      "Logisitic Regression SGD Val f1: 0.602 +- 0.005\n",
      "SVM Huber Val f1: 0.510 +- 0.046\n"
     ]
    }
   ],
   "source": [
    "X = np.array(train_vecs)\n",
    "y = np.array(cong_tweets_data.encoded_party)\n",
    "\n",
    "kf = KFold(5, shuffle=True, random_state=42)\n",
    "cv_lr_acc, cv_lrsgd_acc, cv_svcsgd_acc,  = [], [], []\n",
    "\n",
    "for train_ind, val_ind in kf.split(X, y):\n",
    "    # Assign CV IDX\n",
    "    X_train, y_train = X[train_ind], y[train_ind]\n",
    "    X_val, y_val = X[val_ind], y[val_ind]\n",
    "    \n",
    "    # Scale Data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scale = scaler.fit_transform(X_train)\n",
    "    X_val_scale = scaler.transform(X_val)\n",
    "\n",
    "    # Logisitic Regression\n",
    "    lr = LogisticRegression(\n",
    "        class_weight= 'balanced',\n",
    "        solver='liblinear',\n",
    "        fit_intercept=True\n",
    "    ).fit(X_train_scale, y_train)\n",
    "\n",
    "    y_pred = lr.predict(X_val_scale)\n",
    "    cv_lr_acc.append(accuracy_score(y_val, y_pred))\n",
    "    \n",
    "    # Logistic Regression SGD\n",
    "    sgd = SGDClassifier(\n",
    "        max_iter=1000,\n",
    "        tol=1e-3,\n",
    "        loss='log',\n",
    "        class_weight='balanced'\n",
    "    ).fit(X_train_scale, y_train)\n",
    "    \n",
    "    y_pred = sgd.predict(X_val_scale)\n",
    "    cv_lrsgd_acc.append(accuracy_score(y_val, y_pred))\n",
    "    \n",
    "    # SGD Modified Huber\n",
    "    sgd_huber = SGDClassifier(\n",
    "        max_iter=1000,\n",
    "        tol=1e-3,\n",
    "        alpha=20,\n",
    "        loss='modified_huber',\n",
    "        class_weight='balanced'\n",
    "    ).fit(X_train_scale, y_train)\n",
    "    \n",
    "    y_pred = sgd_huber.predict(X_val_scale)\n",
    "    cv_svcsgd_acc.append(accuracy_score(y_val, y_pred))\n",
    "\n",
    "print(f'Logistic Regression Val f1: {np.mean(cv_lr_f1):.3f} +- {np.std(cv_lr_f1):.3f}')\n",
    "print(f'Logisitic Regression SGD Val f1: {np.mean(cv_lrsgd_f1):.3f} +- {np.std(cv_lrsgd_f1):.3f}')\n",
    "print(f'SVM Huber Val f1: {np.mean(cv_svcsgd_acc):.3f} +- {np.std(cv_svcsgd_acc):.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Val f1: 0.599 +- 0.001\n",
      "Logisitic Regression SGD Val f1: 0.600 +- 0.003\n",
      "SVM Huber Val f1: 0.510 +- 0.046\n"
     ]
    }
   ],
   "source": [
    "print(f'Logistic Regression Val f1: {np.mean(cv_lr_acc):.3f} +- {np.std(cv_lr_acc):.3f}')\n",
    "print(f'Logisitic Regression SGD Val f1: {np.mean(cv_lrsgd_acc):.3f} +- {np.std(cv_lrsgd_acc):.3f}')\n",
    "print(f'SVM Huber Val f1: {np.mean(cv_svcsgd_acc):.3f} +- {np.std(cv_svcsgd_acc):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modelling on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_testing_data['Cleaned_Text_WO_Stopwords'].dropna(inplace=True)\n",
    "test_docs = np.array(cong_testing_data['Cleaned_Text_WO_Stopwords'])\n",
    "test_docs = [doc for doc in test_docs if str(doc) != 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265000\n"
     ]
    }
   ],
   "source": [
    "test_docs = docs_preprocessor(test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in initital documents: 159400\n",
      "Number of unique words after removing rare and common words: 17966\n",
      "Number of unique tokens: 17966\n",
      "Number of documents: 592803\n"
     ]
    }
   ],
   "source": [
    "test_corpus = [train_id2word.doc2bow(text) for text in test_docs]\n",
    "\n",
    "test_vecs = []\n",
    "for i in range(len(cong_testing_data.shape[0])):\n",
    "    top_topics = model.get_document_topics(test_corpus[i], minimum_probability=0.0)\n",
    "    topic_vec = [top_topics[i][1] for i in range(5)]\n",
    "    topic_vec.extend([rev_test.iloc[i].real_counts]) # counts of reviews for restaurant\n",
    "    topic_vec.extend([len(rev_test.iloc[i].text)]) # length review\n",
    "    test_vecs.append(topic_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-fa0b18cafa73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mtest_id2word\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_dictionary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid2token\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mtest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLdaModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_corpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_id2word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_every\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_every\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0muse_numpy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunks_as_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_numpy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m             self.add_lifecycle_event(\n\u001b[0;32m    522\u001b[0m                 \u001b[1;34m\"created\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, corpus, chunksize, decay, offset, passes, update_every, eval_every, iterations, gamma_threshold, chunks_as_numpy)\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0meval_every\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreallen\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlencorpus\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_no\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0meval_every\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumworkers\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_perplexity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_docs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlencorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatcher\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36mlog_perplexity\u001b[1;34m(self, chunk, total_docs)\u001b[0m\n\u001b[0;32m    844\u001b[0m         \u001b[0mcorpus_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnt\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdocument\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcnt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdocument\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    845\u001b[0m         \u001b[0msubsample_ratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtotal_docs\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 846\u001b[1;33m         \u001b[0mperwordbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubsample_ratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubsample_ratio\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msubsample_ratio\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcorpus_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    847\u001b[0m         logger.info(\n\u001b[0;32m    848\u001b[0m             \u001b[1;34m\"%.3f per-word bound, %.1f perplexity estimate based on a held-out corpus of %i documents with %i words\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36mbound\u001b[1;34m(self, corpus, gamma, subsample_ratio)\u001b[0m\n\u001b[0;32m   1110\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bound: at document #%i\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mgamma\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1112\u001b[1;33m                 \u001b[0mgammad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1113\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m                 \u001b[0mgammad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36minference\u001b[1;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[0;32m    708\u001b[0m             \u001b[1;31m# phinorm is the normalizer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m             \u001b[1;31m# TODO treat zeros explicitly, instead of adding epsilon?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m             \u001b[0mphinorm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpElogthetad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpElogbetad\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m             \u001b[1;31m# Iterate between gamma and phi until convergence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Set training parameters.\n",
    "num_topics = range(5,6)\n",
    "chunksize = 100 # size of the doc looked at every pass\n",
    "passes = 20 # number of passes through documents\n",
    "iterations = 400\n",
    "eval_every = 1  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "topic_hp_df = pd.DataFrame(columns = [\"Event Name\",\"Number of Topics\",\"Coherence Score\",\"Perplexity Score\",\"Iterations\",\"Chunksize\",\"Time Taken\",\"Keywords in Topics\"])\n",
    "\n",
    "\n",
    "for num in num_topics:\n",
    "    print(num)\n",
    "    inter_topic_df = pd.DataFrame(columns = [\"Event Name\",\"Number of Topics\",\"Coherence Score\",\"Perplexity Score\",\"Iterations\",\"Chunksize\",\"Time Taken\",\"Keywords in Topics\"])\n",
    "    # Make a index to word dictionary.\n",
    "    if len(test_dictionary)>0:\n",
    "        temp = test_dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "        start = time.time()\n",
    "        test_id2word = test_dictionary.id2token\n",
    "        test_model = LdaModel(corpus=test_corpus, id2word=test_id2word, chunksize=chunksize,alpha='auto', eta='auto', iterations=iterations, num_topics=num,passes=passes, eval_every=eval_every)\n",
    "        end = time.time()\n",
    "        print(end-start)\n",
    "        time_taken = end-start\n",
    "\n",
    "        Y = test_model.print_topics(num_words = 10)\n",
    "        topic_words_list = []\n",
    "        for i in range(0,len(Y)):\n",
    "            #topic_words_list.append(html.Br())\n",
    "            topic_words_list.append(\"Topic \"+str(i+1)+\": \")\n",
    "            X = Y[i][1]\n",
    "            a = X.split(\"+\")\n",
    "            words_str = \"\"\n",
    "            for j in range(0,len(a)):\n",
    "                p = a[j].split(\"*\")[1].replace(\"\\\"\",\"\")\n",
    "                words_str += p\n",
    "            topic_words_list.append(words_str)\n",
    "\n",
    "        perplexity = model.log_perplexity(corpus)\n",
    "        coherence_model_lda = CoherenceModel(model=model, texts=docs, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_lda = coherence_model_lda.get_coherence()\n",
    "        \n",
    "        \n",
    "        inter_topic_df[\"Number of Topics\"] = [num]\n",
    "        inter_topic_df[\"Coherence Score\"] = [coherence_lda]\n",
    "        inter_topic_df[\"Perplexity Score\"] = [perplexity]\n",
    "        inter_topic_df[\"Iterations\"] = [iterations]\n",
    "        inter_topic_df[\"Chunksize\"] = [chunksize]\n",
    "        inter_topic_df[\"Time Taken\"] = [time_taken]\n",
    "        inter_topic_df[\"Keywords in Topics\"] = [topic_words_list]\n",
    "        topic_hp_df = pd.concat([topic_hp_df,inter_topic_df])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
